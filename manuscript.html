<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Qiwen Hu" />
  <meta name="author" content="Casey S. Greene" />
  <meta name="dcterms.date" content="2018-04-24" />
  <meta name="keywords" content="single cell, latent space, variational autoencoder, generative adversarial networls, deep learning" />
  <title>Progress Report: Genome-wide hypothesis generation for single-cell expression via latent spaces of deep neural networks</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="github-pandoc.css">
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <!-- Insert Analytics Script Below -->
  <script>
  </script>
  <!-- End Analytics Script -->
</head>
<body>
<header>
<h1 class="title">Progress Report: Genome-wide hypothesis generation for single-cell expression via latent spaces of deep neural networks</h1>
</header>
<p><small><em> This manuscript was automatically generated from <a href="https://github.com/greenelab/czi-hca-report/tree/3c42d0467c2dbea44b50b7b2829bc59d77902363">greenelab/czi-hca-report@3c42d04</a> on April 24, 2018. </em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>Qiwen Hu</strong><br> <img src="images/orcid.svg" alt="ORCID icon" width="13" height="13" /> <a href="https://orcid.org/None">None</a> · <img src="images/github.svg" alt="GitHub icon" width="13" height="13" /> <a href="https://github.com/huqiwen0313">huqiwen0313</a> · <img src="images/twitter.svg" alt="Twitter icon" width="13" height="13" /> <a href="https://twitter.com/qiwen_hu">qiwen_hu</a><br> <small> Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania </small></p></li>
<li><p><strong>Casey S. Greene</strong><br> <img src="images/orcid.svg" alt="ORCID icon" width="13" height="13" /> <a href="https://orcid.org/0000-0001-8713-9213">0000-0001-8713-9213</a> · <img src="images/github.svg" alt="GitHub icon" width="13" height="13" /> <a href="https://github.com/cgreene">cgreene</a> · <img src="images/twitter.svg" alt="Twitter icon" width="13" height="13" /> <a href="https://twitter.com/greenescientist">greenescientist</a><br> <small> Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania; Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation · Funded by Grant TBD </small></p></li>
</ul>
<h2 id="abstract" class="page_break_before">Abstract</h2>
<p>We wrote an application for the <a href="https://chanzuckerberg.com/wp-content/uploads/2017/03/RFA-Computational-Tools.pdf">Chan Zuckerberg Initiative’s Collaborative Computational Tools RFA</a>. Our application was recommended for funding. We are writing our progress report as we go. This repository contains the report. Please feel free to file a <a href="https://github.com/greenelab/czi-hca-report/issues">GitHub Issue</a> to ask a question. Some elements of this report are expected to also be written up via a published manuscript. In the event that we write a manuscript, we will begin from this report. Authorship will be determined in accordance with <a href="http://www.icmje.org/recommendations/browse/roles-and-responsibilities/defining-the-role-of-authors-and-contributors.html">ICMJE guidelines</a>.</p>
<h2 id="introduction">Introduction</h2>
<p>Currently this contains text describing our project from our <a href="https://github.com/greenelab/czi-rfa/blob/master/proposal.md">initial proposal</a>.</p>
<p>The Human Cell Atlas (HCA) aims to provide a comprehensive map of all types of human cells. Connecting that map to disease states, which will be key to the CZI’s mission of curing or managing all diseases in the next eighty years, will require us to see how these cell types change during aging, during disease processes, or in the presence of drugs. Ideally, we’d be able to apply a transformation to the HCA’s reference map to predict and study these states.</p>
<p>Certain types of deep neural networks can generate hypothetical data by learning and decoding a lower dimensional latent space. An ideal latent space enables arithmetic operations that use data to produce realistic output for novel transformations. For example, FaceApp <span class="citation" data-cites="11SweunvY">[<a href="#ref-11SweunvY">1</a>]</span> can modify a picture of an individual to produce an image of the subject at an older age, with a different expression, or of a different gender.</p>
<p>The overall objective of this proposal is to determine how unsupervised deep neural network models can best be trained on single cell expression data from the HCA and the extent to which such models define biological latent spaces that capture disease states and targeted perturbations. The rationale is that latent space arithmetic for single cell transcriptomes would enable researchers to use predict how the expression of every gene would change in each HCA-identified cell type in numerous conditions including after drug treatment, in the context of a specific genetic variant, with a specific disease, or a combination of these and other factors.</p>
<h3 id="summary">Summary</h3>
<p>Certain deep neural networks can generate hypothetical data by learning and decoding a lower dimensional latent space. This latent space enables arithmetic operations that produce realistic output for novel transformations. This allows users to generate hypothetical images <span class="citation" data-cites="mSTbr0cw">[<a href="#ref-mSTbr0cw">2</a>]</span> and to interpolate protein localizations through the cell-cycle <span class="citation" data-cites="zBCcUQOM">[<a href="#ref-zBCcUQOM">3</a>]</span>. An accessible example of latent space transformations comes from FaceApp <span class="citation" data-cites="11SweunvY">[<a href="#ref-11SweunvY">1</a>]</span>, which modifies a picture of an individual to produce an image of the subject at an older age, with a different expression, or of a different genders.</p>
<p>Our <em>overall objective</em> is to determine how unsupervised deep neural network models can best be trained on single cell expression data from the Human Cell Atlas (HCA) and the extent to which such models define biological latent spaces that capture disease states and targeted perturbations. The <em>rationale</em> is that latent space arithmetic for genomic data would enable researchers to predict how the expression of every gene would change in each HCA-identified cell type after drug treatment, in the context of a specific genetic variant, with a specific disease, or a combination of these and other factors.</p>
<h3 id="prior-contributions-preliminary-results">Prior Contributions / Preliminary Results</h3>
<p>We previously developed neural-network based methods for unsupervised integration of transcriptomic data <span class="citation" data-cites="1CFhfCyWN">[<a href="#ref-1CFhfCyWN">4</a>]</span>. We now build to Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) which have a track record of defining meaningful latent spaces for images. We adapted GANs to generate realistic individuals under a differential privacy framework <span class="citation" data-cites="fbIH12yd">[<a href="#ref-fbIH12yd">7</a>]</span> and built VAEs over bulk transcriptomic data with the goal of describing a biologically-relevant latent space <span class="citation" data-cites="aWn0df1m">[<a href="#ref-aWn0df1m">8</a>]</span>. Here, we will apply these unsupervised deep learning methods to single cell transcriptomic data and incorporate novel data augmentation approaches for genomics. We also bring workflow automation experience to the HCA community <span class="citation" data-cites="Qh7xTLwz">[<a href="#ref-Qh7xTLwz">9</a>]</span>.</p>
<h2 id="aim-1-develop-proof-of-concept-unsupervised-deep-learning-methods-for-single-cell-transcriptomic-data-from-the-hca.">Aim 1: Develop proof-of-concept unsupervised deep learning methods for single cell transcriptomic data from the HCA.</h2>
<h3 id="proposed-work">Proposed work</h3>
<p>The <em>objective of this aim</em> is to implement and test approaches to build deep generative models, such as VAEs <span class="citation" data-cites="NLVTJ9Lj">[<a href="#ref-NLVTJ9Lj">10</a>]</span> and GANs <span class="citation" data-cites="dXnSD8tJ">[<a href="#ref-dXnSD8tJ">11</a>]</span>, from HCA single cell RNA-seq data.</p>
<p>Single cell data pose unique opportunities, but also challenges, for deep neural network algorithms. Many cells are often assayed, and many observations are needed to use deep learning effectively. However, transcript abundance estimates for each cell are generally subject to more error than bulk samples.</p>
<p>In our experience with generative deep learning <span class="citation" data-cites="fbIH12yd">[<a href="#ref-fbIH12yd">7</a>]</span> it can be difficult to predict optimal parameters in advance. We will perform a grid search over VAE architectures and hyperparameters to identify suitable options. We will evaluate zero-inflated loss among more traditional loss functions, as Chris Probert noted potential benefits on our proposal’s GitHub repository <span class="citation" data-cites="ufUaIy3V">[<a href="#ref-ufUaIy3V">12</a>]</span> <span class="citation" data-cites="13Q8I0ueY">[<a href="#ref-13Q8I0ueY">13</a>]</span> <span class="citation" data-cites="6Dv4X61k">[<a href="#ref-6Dv4X61k">14</a>]</span> <span class="citation" data-cites="zALrucGv">[<a href="#ref-zALrucGv">15</a>]</span>]. This process will identify a subset of parameters and architectures that are worth exploring further for single cells.</p>
<p>We will also develop data augmentation for single cell RNA-seq data, as no such approaches exist yet for transcriptomes. To understand data augmentation, imagine scanned pathology slides. Each slide may be prepared and scanned with a subtly different orientation or magnification. A deep learning method may identify these measurement differences, or there may be too few slides to train a good model. Applying arbitrary rotations, zooms, and other irrelevant transformations increases the effective amount of training data and reduces the model’s propensity to learn such noise.</p>
<p>We plan to use fast abundance estimates for RNA-seq <span class="citation" data-cites="vrqQcFyx">[<a href="#ref-vrqQcFyx">16</a>]</span> to perform data augmentation for transcriptomes. Multiple resamples or subsamples of reads during transcript abundance estimation can capture uncertainty in the data, akin to arbitrary rotations. Therefore, we plan to collaborate with Rob Patro’s laboratory (Collaborative Network) to implement these and related approaches. We posit that genomic data augmentation will improve latent feature generalization by separating biological from technical features and increasing the effective sample size during training.</p>
<p>We will select high-quality models by choosing those that minimize both reconstruction loss and KL divergence <span class="citation" data-cites="NLVTJ9Lj">[<a href="#ref-NLVTJ9Lj">10</a>]</span>. We will evaluate resulting models for their applicability to rheumatic disease and their suitability for latent space arithmetic (see: Evaluation).</p>
<h3 id="results">Results</h3>
<h4 id="vae-test-on-simulated-single-cell-datasets">VAE test on simulated single cell datasets</h4>
<h4 id="simulation-data-generation">1. Simulation data generation:</h4>
<p>Simulated single cell data was generated by splatter <span class="citation" data-cites="117yS2Kkv">[<a href="#ref-117yS2Kkv">18</a>]</span>.</p>
<p>Parameters used: * nCells - The number of cells to simulate: 500 - 5000 * nGenes - The number of genes to simulate: 20000 - 60000 * nGroups - The number of celltypes: 5 - 15 * outlier - probability of a gene that is an expression outlier: 0.1 - 0.5 * default parameter is ncells = 600, nGenes = 20000, celltypes = 5, batchsize = 1</p>
<p>Simulation statistics under different parameters:</p>
<figure>
<img src="images/mean.gene.exp.bmp" />
</figure>
<p>Figure 1: Distribution of mean expression level of simulated genes across samples under different simulated parameters.</p>
<h4 id="visualization-of-simulated-single-cell-data-using-vae_depth2-2-hidden-layer-vae_depth1-1-hidden-layer-t-sne-and-pca-under-different-parameters">2. Visualization of simulated single cell data using VAE_depth2 (2 hidden layer), VAE_depth1 (1 hidden layer), t-SNE and PCA under different parameters</h4>
<p>To see if different methods can recover cell types, we compared the 2D visualizations on simulated datasets. 2-layer VAE performs much better to differentiate different cell types when comparing with 1-layer VAE. The performance of VAE and t-SNE is similar and much better than PCA, but with the increase of outlier genes, 2-layer VAE is more resistant to noise.</p>
<figure>
<img src="images/outlier.vis.png" />
</figure>
<p>Figure 2: 2 - layer VAE is more resistant to outlier. 2D visualization of simulated single cell data from different outlier parameters ( 0 - 0.5).</p>
<h4 id="performance-evaluation-of-different-simulation-parameters">3. Performance evaluation of different simulation parameters</h4>
<p>Clustering performance was measured by normalized mutual information (NMI). NMI is an normalization of the Mutual Information (MI, measures the dependence of two random variables). It is a measurement to determine the quality of clustering, which is between 0 (no mutual information) and 1 (perfect correlation).</p>
<figure>
<img src="images/nmi.png" />
</figure>
<p>Figure 3: Performance comparison among VAE, t-SNE and PCA under different simulation parameters.</p>
<h2 id="aim-2-generate-a-benchmark-dataset-of-harmonized-public-data-to-evaluate-the-extent-to-which-hca-cell-types-capture-rheumatic-disease-biology.">Aim 2: Generate a benchmark dataset of harmonized public data to evaluate the extent to which HCA cell types capture rheumatic disease biology.</h2>
<p>The HCA’s partnership with the Immunological Genome Project (immgenH) will provide single-cell gene expression-based immunocyte phenotyping at an unprecedented resolution. A compendium comprised of bulk gene expression data from autoimmune/rheumatic diseases is exceptionally well-suited to evaluating the disease relevance of these immunocyte data. The <em>objective of this aim</em> is to build and share real and simulated benchmark datasets to evaluate the quality of the cell-type signatures. This will allow CZI to evaluate techniques, including VAEs and other methods, for defining cell-type-specific expression signatures from the HCA’s single-cell datasets by measuring their ability to decompose bulk, whole-tissue autoimmune/rheumatic disease data.</p>
<p>We will generate simulated bulk datasets drawn from HCA-identified cell types by combining their expression profiles at different proportions. We will also build a multi-tissue autoimmune/rheumatic disease compendium from existing public datasets that we have curated (currently more than 12,000 samples). This compendium includes samples from patients with systemic lupus erythematosus (SLE), sarcoidosis, and inflammatory bowel disorders among many other diseases. Such a compendium lets us determine the extent to which HCA-derived cell type signatures capture disease-relevant information in a way that matches previous literature. For instance, we expect to detect higher proportions of activated macrophages in lupus nephritis samples than controls <span class="citation" data-cites="2f2lADmF">[<a href="#ref-2f2lADmF">19</a>]</span>.</p>
<p>These bulk compendia (simulated and real data) will enable HCA participants (computational-method and molecular-assay developers) to directly compare approaches where we expect their most immediate translational impact: application to existing datasets to explain disease-relevant phenomena via a single-cell perspective.</p>
<h3 id="results-1">Results</h3>
<p>TBD.</p>
<h2 id="references" class="page_break_before">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs">
<div id="ref-11SweunvY">
<p>1. <strong>FaceApp</strong><em>@faceapp_ai</em> (2018-02-11) <a href="https://www.faceapp.com" class="uri">https://www.faceapp.com</a></p>
</div>
<div id="ref-mSTbr0cw">
<p>2. <strong>DRAW: A Recurrent Neural Network For Image Generation</strong><br />
Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Jimenez Rezende, Daan Wierstra<br />
<em>arXiv</em> (2015-02-16) <a href="https://arxiv.org/abs/1502.04623v2" class="uri">https://arxiv.org/abs/1502.04623v2</a></p>
</div>
<div id="ref-zBCcUQOM">
<p>3. <strong>GANs for Biological Image Synthesis</strong><br />
Anton Osokin, Anatole Chessel, Rafael E. Carazo Salas, Federico Vaggi<br />
<em>arXiv</em> (2017-08-15) <a href="https://arxiv.org/abs/1708.04692v2" class="uri">https://arxiv.org/abs/1708.04692v2</a></p>
</div>
<div id="ref-1CFhfCyWN">
<p>4. <strong>ADAGE-Based Integration of Publicly AvailablePseudomonas aeruginosaGene Expression Data with Denoising Autoencoders Illuminates Microbe-Host Interactions</strong><br />
Jie Tan, John H. Hammond, Deborah A. Hogan, Casey S. Greene<br />
<em>mSystems</em> (2016-01-19) <a href="https://doi.org/10.1128/msystems.00025-15" class="uri">https://doi.org/10.1128/msystems.00025-15</a></p>
</div>
<div id="ref-Hlprh8TG">
<p>5. <strong>Unsupervised Extraction of Stable Expression Signatures from Public Compendia with an Ensemble of Neural Networks</strong><br />
Jie Tan, Georgia Doing, Kimberley A. Lewis, Courtney E. Price, Kathleen M. Chen, Kyle C. Cady, Barret Perchuk, Michael T. Laub, Deborah A. Hogan, Casey S. Greene<br />
<em>Cell Systems</em> (2017-07) <a href="https://doi.org/10.1016/j.cels.2017.06.003" class="uri">https://doi.org/10.1016/j.cels.2017.06.003</a></p>
</div>
<div id="ref-BXscBoDB">
<p>6. <strong>ADAGE signature analysis: differential expression analysis with data-defined gene sets</strong><br />
Jie Tan, Matthew Huyck, Dongbo Hu, Rene A. Zelaya, Deborah A. Hogan, Casey S. Greene<br />
<em>Cold Spring Harbor Laboratory</em> (2017-06-27) <a href="https://doi.org/10.1101/156620" class="uri">https://doi.org/10.1101/156620</a></p>
</div>
<div id="ref-fbIH12yd">
<p>7. <strong>Privacy-preserving generative deep neural networks support clinical data sharing</strong><br />
Brett K. Beaulieu-Jones, Zhiwei Steven Wu, Chris Williams, James Brian Byrd, Casey S. Greene<br />
<em>Cold Spring Harbor Laboratory</em> (2017-07-05) <a href="https://doi.org/10.1101/159756" class="uri">https://doi.org/10.1101/159756</a></p>
</div>
<div id="ref-aWn0df1m">
<p>8. <strong>Extracting a Biologically Relevant Latent Space from Cancer Transcriptomes with Variational Autoencoders</strong><br />
Gregory P. Way, Casey S. Greene<br />
<em>Cold Spring Harbor Laboratory</em> (2017-08-11) <a href="https://doi.org/10.1101/174474" class="uri">https://doi.org/10.1101/174474</a></p>
</div>
<div id="ref-Qh7xTLwz">
<p>9. <strong>Reproducibility of computational workflows is automated using continuous analysis</strong><br />
Brett K Beaulieu-Jones, Casey S Greene<br />
<em>Nature Biotechnology</em> (2017-03-13) <a href="https://doi.org/10.1038/nbt.3780" class="uri">https://doi.org/10.1038/nbt.3780</a></p>
</div>
<div id="ref-NLVTJ9Lj">
<p>10. <strong>Auto-Encoding Variational Bayes</strong><br />
Diederik P Kingma, Max Welling<br />
<em>arXiv</em> (2013-12-20) <a href="https://arxiv.org/abs/1312.6114v10" class="uri">https://arxiv.org/abs/1312.6114v10</a></p>
</div>
<div id="ref-dXnSD8tJ">
<p>11. <strong>Generative Adversarial Networks</strong><br />
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio<br />
<em>arXiv</em> (2014-06-10) <a href="https://arxiv.org/abs/1406.2661v1" class="uri">https://arxiv.org/abs/1406.2661v1</a></p>
</div>
<div id="ref-ufUaIy3V">
<p>12. <strong>Use zero-inflated reconstruction loss · Issue #11 · greenelab/czi-rfa</strong><br />
greenelab<br />
<em>GitHub</em> <a href="https://github.com/greenelab/czi-rfa/issues/11" class="uri">https://github.com/greenelab/czi-rfa/issues/11</a></p>
</div>
<div id="ref-13Q8I0ueY">
<p>13. <strong>ZIFA: Dimensionality reduction for zero-inflated single-cell gene expression analysis</strong><br />
Emma Pierson, Christopher Yau<br />
<em>Genome Biology</em> (2015-11-02) <a href="https://doi.org/10.1186/s13059-015-0805-z" class="uri">https://doi.org/10.1186/s13059-015-0805-z</a></p>
</div>
<div id="ref-6Dv4X61k">
<p>14. <strong>Graphical Models for Zero-Inflated Single Cell Gene Expression</strong><br />
Andrew McDavid, Raphael Gottardo, Noah Simon, Mathias Drton<br />
<em>arXiv</em> (2016-10-19) <a href="https://arxiv.org/abs/1610.05857v1" class="uri">https://arxiv.org/abs/1610.05857v1</a></p>
</div>
<div id="ref-zALrucGv">
<p>15. <strong>CIDR: Ultrafast and accurate clustering through imputation for single-cell RNA-seq data</strong><br />
Peijie Lin, Michael Troup, Joshua W. K. Ho<br />
<em>Genome Biology</em> (2017-03-28) <a href="https://doi.org/10.1186/s13059-017-1188-0" class="uri">https://doi.org/10.1186/s13059-017-1188-0</a></p>
</div>
<div id="ref-vrqQcFyx">
<p>16. <strong>Salmon provides fast and bias-aware quantification of transcript expression</strong><br />
Rob Patro, Geet Duggal, Michael I Love, Rafael A Irizarry, Carl Kingsford<br />
<em>Nature Methods</em> (2017-03-06) <a href="https://doi.org/10.1038/nmeth.4197" class="uri">https://doi.org/10.1038/nmeth.4197</a></p>
</div>
<div id="ref-12KZMHMQl">
<p>17. <strong>Near-optimal probabilistic RNA-seq quantification</strong><br />
Nicolas L Bray, Harold Pimentel, Páll Melsted, Lior Pachter<br />
<em>Nature Biotechnology</em> (2016-04-04) <a href="https://doi.org/10.1038/nbt.3519" class="uri">https://doi.org/10.1038/nbt.3519</a></p>
</div>
<div id="ref-117yS2Kkv">
<p>18. <strong>Splatter: simulation of single-cell RNA sequencing data</strong><br />
Luke Zappia, Belinda Phipson, Alicia Oshlack<br />
<em>Genome Biology</em> (2017-09-12) <a href="https://doi.org/10.1186/s13059-017-1305-0" class="uri">https://doi.org/10.1186/s13059-017-1305-0</a></p>
</div>
<div id="ref-2f2lADmF">
<p>19. <strong>Cross-Species Transcriptional Network Analysis Defines Shared Inflammatory Responses in Murine and Human Lupus Nephritis</strong><br />
C. C. Berthier, R. Bethunaickan, T. Gonzalez-Rivera, V. Nair, M. Ramanujam, W. Zhang, E. P. Bottinger, S. Segerer, M. Lindenmeyer, C. D. Cohen, … M. Kretzler<br />
<em>The Journal of Immunology</em> (2012-06-20) <a href="https://doi.org/10.4049/jimmunol.1103031" class="uri">https://doi.org/10.4049/jimmunol.1103031</a></p>
</div>
</div>
<script>
// AnchorJS minified version below.
// Source https://github.com/bryanbraun/anchorjs/blob/064abdd0987f305933ec4982af6d0c1cf2fd0814/anchor.js

/**
 * AnchorJS - v4.0.0 - 2017-06-02
 * https://github.com/bryanbraun/anchorjs
 * Copyright (c) 2017 Bryan Braun; Licensed MIT
 */
!function(A,e){"use strict";"function"==typeof define&&define.amd?define([],e):"object"==typeof module&&module.exports?module.exports=e():(A.AnchorJS=e(),A.anchors=new A.AnchorJS)}(this,function(){"use strict";function A(A){function e(A){A.icon=A.hasOwnProperty("icon")?A.icon:"",A.visible=A.hasOwnProperty("visible")?A.visible:"hover",A.placement=A.hasOwnProperty("placement")?A.placement:"right",A.class=A.hasOwnProperty("class")?A.class:"",A.truncate=A.hasOwnProperty("truncate")?Math.floor(A.truncate):64}function t(A){var e;if("string"==typeof A||A instanceof String)e=[].slice.call(document.querySelectorAll(A));else{if(!(Array.isArray(A)||A instanceof NodeList))throw new Error("The selector provided to AnchorJS was invalid.");e=[].slice.call(A)}return e}function n(){if(null===document.head.querySelector("style.anchorjs")){var A,e=document.createElement("style");e.className="anchorjs",e.appendChild(document.createTextNode("")),void 0===(A=document.head.querySelector('[rel="stylesheet"], style'))?document.head.appendChild(e):document.head.insertBefore(e,A),e.sheet.insertRule(" .anchorjs-link {   opacity: 0;   text-decoration: none;   -webkit-font-smoothing: antialiased;   -moz-osx-font-smoothing: grayscale; }",e.sheet.cssRules.length),e.sheet.insertRule(" *:hover > .anchorjs-link, .anchorjs-link:focus  {   opacity: 1; }",e.sheet.cssRules.length),e.sheet.insertRule(" [data-anchorjs-icon]::after {   content: attr(data-anchorjs-icon); }",e.sheet.cssRules.length),e.sheet.insertRule(' @font-face {   font-family: "anchorjs-icons";   src: url(data:n/a;base64,AAEAAAALAIAAAwAwT1MvMg8yG2cAAAE4AAAAYGNtYXDp3gC3AAABpAAAAExnYXNwAAAAEAAAA9wAAAAIZ2x5ZlQCcfwAAAH4AAABCGhlYWQHFvHyAAAAvAAAADZoaGVhBnACFwAAAPQAAAAkaG10eASAADEAAAGYAAAADGxvY2EACACEAAAB8AAAAAhtYXhwAAYAVwAAARgAAAAgbmFtZQGOH9cAAAMAAAAAunBvc3QAAwAAAAADvAAAACAAAQAAAAEAAHzE2p9fDzz1AAkEAAAAAADRecUWAAAAANQA6R8AAAAAAoACwAAAAAgAAgAAAAAAAAABAAADwP/AAAACgAAA/9MCrQABAAAAAAAAAAAAAAAAAAAAAwABAAAAAwBVAAIAAAAAAAIAAAAAAAAAAAAAAAAAAAAAAAMCQAGQAAUAAAKZAswAAACPApkCzAAAAesAMwEJAAAAAAAAAAAAAAAAAAAAARAAAAAAAAAAAAAAAAAAAAAAQAAg//0DwP/AAEADwABAAAAAAQAAAAAAAAAAAAAAIAAAAAAAAAIAAAACgAAxAAAAAwAAAAMAAAAcAAEAAwAAABwAAwABAAAAHAAEADAAAAAIAAgAAgAAACDpy//9//8AAAAg6cv//f///+EWNwADAAEAAAAAAAAAAAAAAAAACACEAAEAAAAAAAAAAAAAAAAxAAACAAQARAKAAsAAKwBUAAABIiYnJjQ3NzY2MzIWFxYUBwcGIicmNDc3NjQnJiYjIgYHBwYUFxYUBwYGIwciJicmNDc3NjIXFhQHBwYUFxYWMzI2Nzc2NCcmNDc2MhcWFAcHBgYjARQGDAUtLXoWOR8fORYtLTgKGwoKCjgaGg0gEhIgDXoaGgkJBQwHdR85Fi0tOAobCgoKOBoaDSASEiANehoaCQkKGwotLXoWOR8BMwUFLYEuehYXFxYugC44CQkKGwo4GkoaDQ0NDXoaShoKGwoFBe8XFi6ALjgJCQobCjgaShoNDQ0NehpKGgobCgoKLYEuehYXAAAADACWAAEAAAAAAAEACAAAAAEAAAAAAAIAAwAIAAEAAAAAAAMACAAAAAEAAAAAAAQACAAAAAEAAAAAAAUAAQALAAEAAAAAAAYACAAAAAMAAQQJAAEAEAAMAAMAAQQJAAIABgAcAAMAAQQJAAMAEAAMAAMAAQQJAAQAEAAMAAMAAQQJAAUAAgAiAAMAAQQJAAYAEAAMYW5jaG9yanM0MDBAAGEAbgBjAGgAbwByAGoAcwA0ADAAMABAAAAAAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAH//wAP) format("truetype"); }',e.sheet.cssRules.length)}}this.options=A||{},this.elements=[],e(this.options),this.isTouchDevice=function(){return!!("ontouchstart"in window||window.DocumentTouch&&document instanceof DocumentTouch)},this.add=function(A){var i,o,s,c,r,a,h,l,u,d,f,g,p=[];if(e(this.options),"touch"===(g=this.options.visible)&&(g=this.isTouchDevice()?"always":"hover"),A||(A="h2, h3, h4, h5, h6"),0===(i=t(A)).length)return this;for(n(),o=document.querySelectorAll("[id]"),s=[].map.call(o,function(A){return A.id}),r=0;r<i.length;r++)if(this.hasAnchorJSLink(i[r]))p.push(r);else{if(i[r].hasAttribute("id"))c=i[r].getAttribute("id");else if(i[r].hasAttribute("data-anchor-id"))c=i[r].getAttribute("data-anchor-id");else{u=l=this.urlify(i[r].textContent),h=0;do{void 0!==a&&(u=l+"-"+h),a=s.indexOf(u),h+=1}while(-1!==a);a=void 0,s.push(u),i[r].setAttribute("id",u),c=u}d=c.replace(/-/g," "),(f=document.createElement("a")).className="anchorjs-link "+this.options.class,f.href="#"+c,f.setAttribute("aria-label","Anchor link for: "+d),f.setAttribute("data-anchorjs-icon",this.options.icon),"always"===g&&(f.style.opacity="1"),""===this.options.icon&&(f.style.font="1em/1 anchorjs-icons","left"===this.options.placement&&(f.style.lineHeight="inherit")),"left"===this.options.placement?(f.style.position="absolute",f.style.marginLeft="-1em",f.style.paddingRight="0.5em",i[r].insertBefore(f,i[r].firstChild)):(f.style.paddingLeft="0.375em",i[r].appendChild(f))}for(r=0;r<p.length;r++)i.splice(p[r]-r,1);return this.elements=this.elements.concat(i),this},this.remove=function(A){for(var e,n,i=t(A),o=0;o<i.length;o++)(n=i[o].querySelector(".anchorjs-link"))&&(-1!==(e=this.elements.indexOf(i[o]))&&this.elements.splice(e,1),i[o].removeChild(n));return this},this.removeAll=function(){this.remove(this.elements)},this.urlify=function(A){var t=/[& +$,:;=?@"#{}|^~[`%!'<>\]\.\/\(\)\*\\]/g;return this.options.truncate||e(this.options),A.trim().replace(/\'/gi,"").replace(t,"-").replace(/-{2,}/g,"-").substring(0,this.options.truncate).replace(/^-+|-+$/gm,"").toLowerCase()},this.hasAnchorJSLink=function(A){var e=A.firstChild&&(" "+A.firstChild.className+" ").indexOf(" anchorjs-link ")>-1,t=A.lastChild&&(" "+A.lastChild.className+" ").indexOf(" anchorjs-link ")>-1;return e||t||!1}}return A});

// Enable links for selected headers
var anchors = new AnchorJS();
anchors.add("h2, h3, h4")
</script>
<!-- Enable Hypothesis annotation. https://web.hypothes.is/ -->
<script src="https://hypothes.is/embed.js" async></script>
</body>
</html>
